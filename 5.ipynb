{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA0HPVmIBT4C",
        "outputId": "857cf81c-c6b3-4b99-f830-1eaddad22ac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files...\n",
            "Unzipping files...\n",
            "Merging training data...\n",
            "Cleaning up...\n",
            "Data ready.\n"
          ]
        }
      ],
      "source": [
        "# Note: After you run this cell, the training and test data will be available in\n",
        "# the file browser. (Click the folder icon on the left to view it)\n",
        "#\n",
        "# If you don't see the data after the cell completes, click the refresh button\n",
        "# in the file browser (folder icon with circular arrow)\n",
        "\n",
        "# First, let's download and unzip the data\n",
        "!echo \"Downloading files...\"\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_partial.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_classes_partial.csv\n",
        "\n",
        "!echo \"Unzipping files...\"\n",
        "!unzip -q /content/training1.zip\n",
        "!unzip -q /content/training2.zip\n",
        "!unzip -q /content/test.zip\n",
        "!unzip -q /content/test_partial.zip\n",
        "\n",
        "# Combine the two traning directories\n",
        "!echo \"Merging training data...\"\n",
        "!mkdir /content/training\n",
        "!mv /content/training1/* /content/training\n",
        "!mv /content/training2/* /content/training\n",
        "\n",
        "# Cleanup\n",
        "!echo \"Cleaning up...\"\n",
        "!rmdir /content/training1\n",
        "!rmdir /content/training2\n",
        "!rm training1.zip\n",
        "!rm training2.zip\n",
        "!rm test.zip\n",
        "!rm test_partial.zip\n",
        "\n",
        "!echo \"Data ready.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tf-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sy0K9d94ZBkw",
        "outputId": "a623947f-e5ff-43cd-a5ba-a6356de7b6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.9.0.dev20220311-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (499.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 499.4 MB 29 kB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.0.0)\n",
            "Collecting keras-nightly~=2.9.0.dev\n",
            "  Downloading keras_nightly-2.9.0.dev2022031108-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.10.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Collecting tf-estimator-nightly~=2.9.0.dev\n",
            "  Downloading tf_estimator_nightly-2.9.0.dev2022031109-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 22.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.44.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.21.5)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (21.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.24.0)\n",
            "Collecting tb-nightly~=2.9.0.a\n",
            "  Downloading tb_nightly-2.9.0a20220310-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 22.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.9.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.9.0.a->tf-nightly) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.9.0.a->tf-nightly) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.9.0.a->tf-nightly) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-nightly) (3.0.7)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-nightly, gast, tf-nightly\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, but you have tf-estimator-nightly 2.9.0.dev2022031109 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.4.0 keras-nightly-2.9.0.dev2022031108 tb-nightly-2.9.0a20220310 tf-estimator-nightly-2.9.0.dev2022031109 tf-nightly-2.9.0.dev20220311\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF7USssdNuDh",
        "outputId": "6b1a6d80-87cf-414a-afc6-a8b9a33fac90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31368 images belonging to 43 classes.\n",
            "Found 7841 images belonging to 43 classes.\n"
          ]
        }
      ],
      "source": [
        "# We're using keras' ImageDataGenerator class to load our image data.\n",
        "# See (https://keras.io/api/preprocessing/image/#imagedatagenerator-class) for details\n",
        "#\n",
        "# A couple of things to note:\n",
        "# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.\n",
        "# 2. Class names are inferred automatically from the image subdirectory names.\n",
        "# 3. We're splitting the training data into 80% training, 20% validation. \n",
        "\n",
        "\n",
        "training_dir = '/content/training/'\n",
        "image_size = (100, 100)\n",
        "\n",
        "# Split up the training data images into training and validations sets\n",
        "# We'll use and ImageDataGenerator to do the splits\n",
        "# ImageDataGenerator can also be used to do preprocessing and agumentation on the files as can be seen with rescale\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=.2\n",
        "        )\n",
        "validation_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=.2\n",
        "        )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        training_dir,\n",
        "        target_size = image_size,\n",
        "        subset=\"training\",\n",
        "        batch_size=32,\n",
        "        class_mode='sparse',\n",
        "        seed=42,shuffle=True)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        training_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='sparse',\n",
        "        subset=\"validation\",\n",
        "        seed=42)\n",
        "\n",
        "# batch_size = 32\n",
        "# img_height = 100\n",
        "# img_width = 100\n",
        "\n",
        "# train_generator = tf.keras.utils.image_dataset_from_directory(\n",
        "#   training_dir,\n",
        "#   validation_split=0.2,\n",
        "#   subset=\"training\",\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)\n",
        "\n",
        "# validation_generator = tf.keras.utils.image_dataset_from_directory(\n",
        "#   training_dir,\n",
        "#   validation_split=0.2,\n",
        "#   subset=\"validation\",\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnGBwGVZPyyh",
        "outputId": "bfab761f-5160-45df-f4a2-9f707cd47e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7185b71f7cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfirst_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'tolist'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # View 9 images and their class labels\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for images, labels in train_generator:\n",
        "#     for i in range(9):\n",
        "#         first_image = images.tolist()[i]      \n",
        "#         ax = plt.subplot(3, 3, i + 1)\n",
        "#         f = np.array(first_image)*255\n",
        "#         plt.imshow(f.astype(\"uint8\"))\n",
        "#         plt.title(int(labels[i]))\n",
        "#         plt.axis(\"off\")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVSfaqgKPzE2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "388a1c4e-5992-45ec-b9bf-901f93a38089"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-96a27ec354ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomBrightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.layers' has no attribute 'RandomBrightness'"
          ]
        }
      ],
      "source": [
        "# Build a model...\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.GaussianNoise(.01, input_shape=(100,100,3)))\n",
        "model.add(layers.RandomContrast(factor=[0,1]))\n",
        "model.add(layers.RandomRotation(factor=0.05))\n",
        "# model.add(layers.RandomBrightness(factor=.5))\n",
        "model.add(layers.Conv2D(100, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(43, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "0AfhBKgVsiFo",
        "outputId": "41079d85-4ceb-43f6-c456-326dac903230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gaussian_noise (GaussianNoi  (None, 100, 100, 3)      0         \n",
            " se)                                                             \n",
            "                                                                 \n",
            " random_contrast (RandomCont  (None, 100, 100, 3)      0         \n",
            " rast)                                                           \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 100, 100, 3)      0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " random_brightness (RandomBr  (None, 100, 100, 3)      0         \n",
            " ightness)                                                       \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 98, 98, 100)       2800      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 49, 100)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 47, 64)        57664     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 43)                2795      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,787\n",
            "Trainable params: 669,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dbdoS23ctGwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator"
      ],
      "metadata": {
        "id": "WjH23PqgvljU",
        "outputId": "ae09ec17-75c1-47e3-9ec6-2b42663777a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7fae07a81c10>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=5, \n",
        "                    validation_data=(validation_generator))"
      ],
      "metadata": {
        "id": "STDXVYaGvEjK",
        "outputId": "0f93b7a7-545c-4306-db78-c760b6fdcd97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8fc670ecb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f8fc670ecb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "981/981 [==============================] - ETA: 0s - loss: 0.8768 - accuracy: 0.7505WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f90300c6ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f90300c6ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "981/981 [==============================] - 33s 33ms/step - loss: 0.8768 - accuracy: 0.7505 - val_loss: 0.4853 - val_accuracy: 0.8577\n",
            "Epoch 2/5\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.1528 - accuracy: 0.9563 - val_loss: 0.3745 - val_accuracy: 0.8865\n",
            "Epoch 3/5\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.0904 - accuracy: 0.9753 - val_loss: 0.2000 - val_accuracy: 0.9459\n",
            "Epoch 4/5\n",
            "981/981 [==============================] - 33s 34ms/step - loss: 0.0729 - accuracy: 0.9792 - val_loss: 0.2214 - val_accuracy: 0.9383\n",
            "Epoch 5/5\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.0591 - accuracy: 0.9838 - val_loss: 0.7281 - val_accuracy: 0.8396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)"
      ],
      "metadata": {
        "id": "SDXbwrs30k_F",
        "outputId": "a9b78f71-c9d4-438a-aab1-bdbf1546d99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "246/246 - 6s - loss: 0.1810 - accuracy: 0.9545 - 6s/epoch - 24ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDc0xuoZs3DK"
      },
      "source": [
        "## Testing the model\n",
        "Once you have built and trained your model, the next step is to run the test images through it and see how well your model does at making predictions for images it has never seen before. \n",
        "\n",
        "Since loading these images and formatting them for the model can be tricky, you may find the following code useful. This code only uses your model to predict the class label for a given image. You'll still need to compare those predictions to the \"ground truth\" class labels in `test_classes_partial.csv` to evaluate how well the model does.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['test_partial'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['test_partial'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]"
      ],
      "metadata": {
        "id": "H3NEHJRL06Mg",
        "outputId": "21b491d3-f5f5-4e23-9b07-9ebf120e5a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 201 images belonging to 1 classes.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f8fc6769b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f8fc6769b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(predictions).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i1N0uCsM6Kp",
        "outputId": "3eb5ca2d-fd06-4d61-ee0a-d30dc8faecbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     15\n",
              "10    15\n",
              "11    14\n",
              "13    10\n",
              "9     10\n",
              "3      9\n",
              "4      9\n",
              "5      9\n",
              "25     8\n",
              "38     8\n",
              "2      8\n",
              "17     8\n",
              "33     7\n",
              "12     7\n",
              "7      7\n",
              "18     6\n",
              "16     5\n",
              "35     5\n",
              "8      4\n",
              "21     4\n",
              "30     4\n",
              "6      4\n",
              "20     3\n",
              "28     2\n",
              "31     2\n",
              "29     2\n",
              "14     2\n",
              "26     2\n",
              "24     2\n",
              "40     2\n",
              "36     2\n",
              "19     1\n",
              "34     1\n",
              "23     1\n",
              "22     1\n",
              "15     1\n",
              "41     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_df = pd.read_csv('/content/test_classes_partial.csv')\n",
        "\n",
        "correct_df['predictions'] = predictions\n",
        "\n",
        "conditions = [correct_df['predictions'] > correct_df['ClassId'], correct_df['predictions'] < correct_df['ClassId']]\n",
        "choices = [1,1]\n",
        "\n",
        "correct_df['missed'] = np.select(conditions, choices, default=0)\n",
        "correct_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5Rhjl7JNKJi1",
        "outputId": "4ac2da0b-77ba-4680-8aaa-63772eb07c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Filename  ClassId  predictions  missed\n",
              "0    00000.jpg       16           16       0\n",
              "1    00001.jpg        1            1       0\n",
              "2    00002.jpg       38           38       0\n",
              "3    00003.jpg       33           33       0\n",
              "4    00004.jpg       11           11       0\n",
              "..         ...      ...          ...     ...\n",
              "196  00196.jpg        8            8       0\n",
              "197  00197.jpg       38            5       1\n",
              "198  00198.jpg       18           31       1\n",
              "199  00199.jpg       28           28       0\n",
              "200  00200.jpg       17           17       0\n",
              "\n",
              "[201 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-652f8198-4a8f-43f1-90cf-c55ff144df7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>predictions</th>\n",
              "      <th>missed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000.jpg</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00002.jpg</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00003.jpg</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00004.jpg</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>00196.jpg</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>00197.jpg</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>00198.jpg</td>\n",
              "      <td>18</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>00199.jpg</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>00200.jpg</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>201 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-652f8198-4a8f-43f1-90cf-c55ff144df7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-652f8198-4a8f-43f1-90cf-c55ff144df7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-652f8198-4a8f-43f1-90cf-c55ff144df7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_df.missed.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn9JlfzILEv3",
        "outputId": "0fb79bbd-7141-4a08-b198-31eb1102097e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodPABZ-Yz-6"
      },
      "source": [
        "##Partial Hold out Dataset\n",
        "You're given the answers to the first 200 images in the hold out dataset. \n",
        "\n",
        "Once you have predictions for the partial holdout dataset, you'll need to compare those predictions against the \"ground truth\" class labels in `test_classes_partial.csv` to evaluate how well the model does. \n",
        "\n",
        "Make sure to use the insights gained from the partial hold out dataset in your executive summary.\n",
        "\n",
        "Once you feel confident, you will need to predict for the full test dataset using the following code, and submit your csv file:\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['test'],\n",
        "        target_size=image_size,\n",
        "        class_mode='sparse',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "predictions = [np.argmax(probas) for probas in probabilities]\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bret_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}